{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_clustering.ipynb","provenance":[],"collapsed_sections":["ACMgO85KDpBK"],"mount_file_id":"1gCcDQ4FkJgUwKy_AZfiEMj_xFhmOCFdp","authorship_tag":"ABX9TyP1jYtjdGU8p7or4vhgqq39"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"emubCLkhqx0e"},"source":["# Libraries\n","\n","Restart your kernel afterwards!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZfOEBqr6PwG","executionInfo":{"status":"ok","timestamp":1638209240645,"user_tz":360,"elapsed":29394,"user":{"displayName":"Rodolfo Figueroa Soriano","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04776960717726066576"}},"outputId":"b38450c5-4986-42e6-fc28-f8677bde98f9"},"source":["!pip install -U \\\n","    scikit-learn imbalanced-learn scikit-multilearn \\\n","    umap-learn pynndescent numba \\\n","    adjustText \\\n","    yellowbrick datascience albumentations \\\n","    git+https://github.com/scikit-learn-contrib/hdbscan.git#egg=hdbscan\n","    \n","\n","# Second to last line is so pip doesn't throw a fit"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hdbscan\n","  Cloning https://github.com/scikit-learn-contrib/hdbscan.git to /tmp/pip-install-29g76izv/hdbscan_275da23193fd4e03a8853a2cb00d72fd\n","  Running command git clone -q https://github.com/scikit-learn-contrib/hdbscan.git /tmp/pip-install-29g76izv/hdbscan_275da23193fd4e03a8853a2cb00d72fd\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.2)\n","Requirement already satisfied: pynndescent in /usr/local/lib/python3.7/dist-packages (0.5.5)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.54.1)\n","Requirement already satisfied: adjustText in /usr/local/lib/python3.7/dist-packages (0.7.3)\n","Requirement already satisfied: yellowbrick in /usr/local/lib/python3.7/dist-packages (1.3.post1)\n","Requirement already satisfied: datascience in /usr/local/lib/python3.7/dist-packages (0.10.6)\n","Collecting datascience\n","  Downloading datascience-0.17.0.tar.gz (721 kB)\n","\u001b[K     |████████████████████████████████| 721 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n","Collecting albumentations\n","  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n","\u001b[K     |████████████████████████████████| 102 kB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.20.3)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.15.0)\n","Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.24)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n","Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.7/dist-packages (from pynndescent) (0.37.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from adjustText) (3.2.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from yellowbrick) (0.11.0)\n","Collecting yellowbrick\n","  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 57.1 MB/s \n","\u001b[?25h  Downloading yellowbrick-1.3-py3-none-any.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 58.8 MB/s \n","\u001b[?25h  Downloading yellowbrick-1.2.1-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 58.3 MB/s \n","\u001b[?25h  Downloading yellowbrick-1.2-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (2.8.2)\n","Collecting folium>=0.9.1\n","  Downloading folium-0.12.1.post1-py2.py3-none-any.whl (95 kB)\n","\u001b[K     |████████████████████████████████| 95 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from datascience) (1.8.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datascience) (1.1.5)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from datascience) (5.5.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from datascience) (4.4.1)\n","Requirement already satisfied: branca in /usr/local/lib/python3.7/dist-packages (from datascience) (0.4.2)\n","Collecting nbsphinx\n","  Downloading nbsphinx-0.8.7-py3-none-any.whl (25 kB)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from datascience) (3.6.4)\n","Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from datascience) (3.7.1)\n","Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from datascience) (0.5)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from datascience) (2.3.3)\n","Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from folium>=0.9.1->datascience) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium>=0.9.1->datascience) (2.23.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->folium>=0.9.1->datascience) (2.0.1)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n","Collecting opencv-python-headless>=4.1.1\n","  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n","\u001b[K     |████████████████████████████████| 47.6 MB 88 kB/s \n","\u001b[?25hCollecting qudida>=0.0.4\n","  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->datascience) (5.1.1)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->datascience) (21.3)\n","Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from coveralls->datascience) (0.6.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.9.1->datascience) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.9.1->datascience) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.9.1->datascience) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.9.1->datascience) (2.10)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (0.7.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->datascience) (0.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->datascience) (0.2.5)\n","Requirement already satisfied: nbconvert!=5.4 in /usr/local/lib/python3.7/dist-packages (from nbsphinx->datascience) (5.6.1)\n","Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from nbsphinx->datascience) (0.17.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from nbsphinx->datascience) (5.1.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.7.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (1.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (4.1.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.8.4)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->datascience) (4.9.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat->nbsphinx->datascience) (0.2.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->nbsphinx->datascience) (2.6.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->datascience) (0.7.12)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->datascience) (2.2.0)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->datascience) (2.9.1)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->datascience) (1.3.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->datascience) (1.2.4)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx->datascience) (2018.9)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert!=5.4->nbsphinx->datascience) (0.5.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->datascience) (0.7.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->datascience) (1.3.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->datascience) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->datascience) (8.11.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->datascience) (1.11.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->datascience) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->datascience) (1.4.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->datascience) (1.1.5)\n","Building wheels for collected packages: datascience\n","  Building wheel for datascience (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for datascience: filename=datascience-0.17.0-py3-none-any.whl size=726848 sha256=b3f282af56e3e089c3b9c8b1debc4484467e8cf2d21d0c6e8d361212afe7078f\n","  Stored in directory: /root/.cache/pip/wheels/41/e0/1b/bc890a517ad4212eb7180ccca6497c97d0ca7c28342b236888\n","Successfully built datascience\n","Installing collected packages: opencv-python-headless, qudida, nbsphinx, folium, yellowbrick, datascience, albumentations\n","  Attempting uninstall: folium\n","    Found existing installation: folium 0.8.3\n","    Uninstalling folium-0.8.3:\n","      Successfully uninstalled folium-0.8.3\n","  Attempting uninstall: yellowbrick\n","    Found existing installation: yellowbrick 1.3.post1\n","    Uninstalling yellowbrick-1.3.post1:\n","      Successfully uninstalled yellowbrick-1.3.post1\n","  Attempting uninstall: datascience\n","    Found existing installation: datascience 0.10.6\n","    Uninstalling datascience-0.10.6:\n","      Successfully uninstalled datascience-0.10.6\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-1.1.0 datascience-0.17.0 folium-0.12.1.post1 nbsphinx-0.8.7 opencv-python-headless-4.5.4.60 qudida-0.0.4 yellowbrick-1.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"jgtup0vsvZP_"},"source":["# Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"KNGilfpc4Vgm"},"source":["Root path with all subdirectories:"]},{"cell_type":"code","metadata":{"id":"TsYVw8YT2rf3","executionInfo":{"status":"ok","timestamp":1638208842257,"user_tz":360,"elapsed":371,"user":{"displayName":"Rodolfo Figueroa Soriano","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04776960717726066576"}}},"source":["ROOT_PATH = \"./drive/MyDrive/spotify/\""],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qL2Wjr8f4adu"},"source":["Import libraries:"]},{"cell_type":"code","metadata":{"id":"qJLMh-iYBqVV","colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"status":"error","timestamp":1638209295235,"user_tz":360,"elapsed":18702,"user":{"displayName":"Rodolfo Figueroa Soriano","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04776960717726066576"}},"outputId":"9738d6cd-aaa7-4765-b9bd-3e8957f2f9dc"},"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from adjustText import adjust_text\n","\n","import umap\n","import hdbscan.flat as hdflat\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","from skmultilearn.model_selection import iterative_train_test_split\n","\n","import os\n","import uuid\n","import base64\n","import pickle\n","import csv\n","from ast import literal_eval\n","\n","import sys\n","sys.path.append(os.path.join(ROOT_PATH, 'notebooks'))\n","from utils import *"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_dep_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3015\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   2812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: _DistInfoDistribution__dep_map","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_parsed_pkg_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   2812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: _pkg_info","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-408bb784f54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madjustText\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madjust_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhdflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/umap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplefilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mumap_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpynndescent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNNDescent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynndescent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamed_distances\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpynn_named_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynndescent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_named_distances\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpynn_sparse_named_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pynndescent/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHREADING_LAYER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"workqueue\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pynndescent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected string, Requirement, or Distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mincluded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwere\u001b[0m \u001b[0malready\u001b[0m \u001b[0mactivated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mworking\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0mneeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneeded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# push the new requirements onto the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mnew_requirements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_requirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequires\u001b[0;34m(self, extras)\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;34m\"\"\"List of Requirements needed for this distro if `extras` are used\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m         \u001b[0mdeps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdeps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_dep_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3016\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_compute_dependencies\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;31m# Including any condition expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3027\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parsed_pkg_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Requires-Dist'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3028\u001b[0m             \u001b[0mreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_parsed_pkg_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3007\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3008\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPKG_INFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_metadata_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/lib/python3.7/dist-packages/numba-0.51.2.dist-info/METADATA'"]}]},{"cell_type":"markdown","metadata":{"id":"ACMgO85KDpBK"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"91398Fjdvfv0"},"source":["First, we define a function to convert between Spotify ID's (22 character alphanumeric) and UUIDs, to use with PostgreSQL."]},{"cell_type":"code","metadata":{"id":"Sm8UMKTK6ZnP"},"source":["def to_uuid(s_id):\n","    return str(uuid.UUID(bytes=base64.urlsafe_b64decode(s_id + '==')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NKCSgr7kxo9b"},"source":["Then, we set the columns with numerical features:"]},{"cell_type":"code","metadata":{"id":"tkbG21UX6ekg"},"source":["feature_cols =  ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66jpLPmgxr1x"},"source":["Our aggregated CSV generated with Postgres has columns with the pattern <feature>_avg. We define these names and read them with Pandas:"]},{"cell_type":"code","metadata":{"id":"OQj_gFyL6gac"},"source":["artist_cols = ['id'] + [c + '_avg' for c in feature_cols]\n","df_artists = pd.read_csv(\n","    os.path.join(ROOT_PATH, '/raw/artists_aggregated.csv'), \n","    usecols = artist_cols\n",")\n","df_artists = df_artists.dropna()\n","artist_ids = df_artists['id']\n","df_artists = df_artists.drop('id', axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SIBcGQ-bx6qU"},"source":["We additionally read a file containing artist information such as ID, name and, most importantly, associated genres:"]},{"cell_type":"code","metadata":{"id":"Zv6nKpWw6kg2"},"source":["df_artists_genres = pd.read_csv(\n","    os.path.join(ROOT_PATH, '/raw/artists_filtered.csv'),\n","    usecols = ['id', 'name', 'followers', 'genres']\n",")\n","df_artists_genres['id_orig'] = df_artists_genres['id']\n","df_artists_genres = df_artists_genres.set_index('id_orig')\n","df_artists_genres['id'] = df_artists_genres['id'].apply(to_uuid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bXauJgbyFC3"},"source":["We standardize all of the numerical features in our DataFrame:"]},{"cell_type":"code","metadata":{"id":"bb5-x-kLCS2Y"},"source":["sc = StandardScaler()\n","df_artists_scaled = sc.fit_transform(df_artists.to_numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1Rumr4dyNha"},"source":["Finally, we perform dimensionality reduction using UMAP. We cache the results for given hyperparameters so that we can reuse them:"]},{"cell_type":"code","metadata":{"id":"wlGKGshdCQEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638146164856,"user_tz":360,"elapsed":12574,"user":{"displayName":"Rodolfo Figueroa Soriano","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04776960717726066576"}},"outputId":"9a005bd6-fdd8-4b8e-f448-300a9e1dd3b5"},"source":["n_neighbors = 60\n","n_clusters = 7\n","min_cluster_size = 10000\n","\n","n_components = 2\n","densmap = False\n","\n","if 'loudness' in feature_cols:\n","    root = os.path.join(ROOT_PATH, '/pickles/loud/')\n","else:\n","    root = os.path.join(ROOT_PATH, '/pickles/no_loud/')\n","\n","if densmap:\n","    suffix = f\"{n_neighbors}_{n_components}_1_{dens_lambda}.pkl\"\n","else:\n","    suffix = f\"{n_neighbors}_{n_components}_0.pkl\"\n","\n","embed_path = root + \"embed_\" + suffix\n","model_path = root + \"model_\" + suffix\n","\n","if os.path.exists(embed_path) and os.path.exists(model_path): # If cache file for given parameters exists, read it\n","    with open(model_path, 'rb') as f:\n","        umap_model = pickle.load(f)\n","    with open(embed_path, 'rb') as f:\n","        artists_embedded = pickle.load(f)\n","else:                                                         # Else, perform UMAP and save\n","    umap_model = umap.UMAP(\n","        n_neighbors = n_neighbors,\n","        n_components = n_components,\n","        min_dist = 0.0,\n","        random_state = 42,\n","        low_memory = False,\n","        n_jobs = -1,\n","        verbose = True,\n","    )\n","\n","    artists_embedded = umap_model.fit_transform(df_artists_scaled)\n","    with open(embed_path, 'wb') as f:\n","        pickle.dump(artists_embedded, f)\n","    with open(model_path, 'wb') as f:\n","        pickle.dump(umap_model, f)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov 29 00:36:01 2021 Building and compiling search function\n"]}]},{"cell_type":"markdown","metadata":{"id":"aFFssSQIy-61"},"source":["Afterwards, we cluster using HDBSCAN:"]},{"cell_type":"code","metadata":{"id":"x_voVsfqy-ju"},"source":["scan = hdflat.HDBSCAN_flat(\n","    artists_embedded,\n","    min_cluster_size = min_cluster_size,\n","    min_samples = 1,\n","    n_clusters = n_clusters,\n","    memory = './cache/',\n","    cluster_selection_method = 'leaf',\n","    gen_min_span_tree = True,\n",")\n","\n","labels = scan.labels_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bnnZsPIoyr15"},"source":["We create an auxiliary DataFrame with the artists' names, IDs, and projected coordinates:"]},{"cell_type":"code","metadata":{"id":"CuRVFQ-nDf6n"},"source":["df_embed = pd.DataFrame(artist_ids)\n","df_embed = df_embed.merge(df_artists_genres, on='id')\n","df_embed['x'] = artists_embedded[:,0]\n","df_embed['y'] = artists_embedded[:,1]\n","if artists_embedded.shape[1] == 3:\n","    df_embed['z'] = artists_embedded[:,2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EMgThiQLyxWo"},"source":["Additionally, we extract the most popular artists for visualization:"]},{"cell_type":"code","metadata":{"id":"NgWUCV0WyxxT"},"source":["df_popular = df_embed.sort_values('followers', ascending=False).head(50)\n","label_text = list(df_popular['name'])\n","label_coords = df_popular[['x', 'y']].to_numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpgQeuA7y3An"},"source":["We create two DataFrames; `df_cluster_hit` contains all the points that HDBSCAN tagged as belonging to a cluster, and `df_cluster_miss` those that it determined to be noise:"]},{"cell_type":"code","metadata":{"id":"XyUzwriNElFH"},"source":["df_cluster = df_embed.copy()\n","df_cluster['cluster'] = labels\n","df_cluster = df_cluster.set_index('id')\n","\n","df_cluster_hit = df_cluster[df_cluster['cluster'] != -1]\n","df_cluster_miss = df_cluster[df_cluster['cluster'] == -1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kaACMYKrzz0M"},"source":["We count how many times each genre appears in each cluster, and assign it to the one it appears on the most. The resulting dictionary `genre_map` has entries of the form `(genre name, assigned cluster)`.\n","\n","Additionally, we create a list with only the `k` most common genres for each cluster (`cluster_genre_map`). We will use all songs belonging to these genres for the classification task."]},{"cell_type":"code","metadata":{"id":"9S-yJuROzzcw"},"source":["genre_cluster_map = genre_clusters(df_cluster_hit)\n","cluster_genre_map = cluster_genres(df_cluster_hit)\n","cluster_genre_map = [set(list(cluster_genre_map[i][0][:5])) for i in range(n_clusters)]\n","\n","genre_map = {}\n","for genre, (labels, counts) in genre_cluster_map.items():\n","    if counts[0] >= 10:\n","        genre_map[genre] = labels[0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t_cZdxWNzNMm"},"source":["Since an artist can have multiple genres, we need a way to determine which artists belong to each cluster. We do this via the dictionary `artist_map`, which has entries of the form `(artist id, list of clusters)`.\n","\n","Moreover, an artist can be representative of several genres in the same cluster. For example, Skrillex is tagged as both \"EDM\" and \"brostep\", both of which belong to the \"electronica\" cluster. Since the individual genre labels are important for the classification task, we create a second dictionary, `artist_map_2`, which has all the genres an artist belongs to, and their corresponding cluster."]},{"cell_type":"code","metadata":{"id":"MpaSYv1nvbLm"},"source":["2artist_genres = df_artists_genres['genres'].to_dict()\n","artist_map = {}\n","artist_map_2 = {}\n","\n","for artist, genre_str in artist_genres.items():\n","    genres = literal_eval(genre_str)\n","    clusters, clusters_2 = set(), set()\n","    for genre in genres:\n","        if genre in genre_map:\n","            clusters.add(genre_map[genre])\n","        for i, genre_set in enumerate(cluster_genre_map):\n","            if genre in genre_set:\n","                clusters_2.add((i, genre))\n","                break\n","    \n","    if clusters:\n","        artist_map[artist] = list(clusters)\n","    if clusters_2:\n","        artist_map_2[artist] = list(clusters_2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZZdqbXNDEWY"},"source":["# Files"]},{"cell_type":"markdown","metadata":{"id":"lTm-w_ui46uD"},"source":["We set the save path for our files for the given set of hyperparameters:"]},{"cell_type":"code","metadata":{"id":"8RNKr370DEoR"},"source":["all_features = feature_cols + ['key', 'mode', 'time_signature', 'explicit', 'duration_ms']\n","if 'loudness' in feature_cols:\n","    training_path = os.path.join(ROOT_PATH, f'/training/loud/{min_cluster_size}/{n_clusters}/')\n","else:\n","    training_path = os.path.join(ROOT_PATH, f'/training/no_loud/{min_cluster_size}/{n_clusters}/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9K2yRir4_8N"},"source":["Since our songs file (`songs_merged.csv`) is too big to load on memory, we have to iterate through it line-by-line:"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"F0Q1MY8WDF_W"},"source":["fields_genres = ['id'] + all_features + ['genre']\n","\n","cluster_files = [None] * n_clusters\n","cluster_writers = [None] * n_clusters\n","for i in range(n_clusters):\n","    cluster_files[i] = open(os.path.join(training_path, f'/genres/examples{i}.csv'), 'w')\n","    cluster_writers[i] = csv.DictWriter(cluster_files[i], fields_genres)\n","    cluster_writers[i].writeheader()\n","\n","with \\\n","    open(os.path.join(ROOT_PATH, '/raw/songs_merged.csv'), 'r') as f, \\\n","    open(os.path.join(training_path, 'supergenres/clusters.csv'), 'w') as f_write:\n","    reader = csv.DictReader(f)\n","\n","    fields = ['id'] + all_features + ['cluster']\n","    writer = csv.DictWriter(f_write, fields)\n","    writer.writeheader()\n","    \n","    for row in reader:\n","        flag = False\n","        \n","        to_write = {}\n","        for feature in all_features:\n","            try:\n","                to_write[feature] = float(row[feature])\n","            except Exception:\n","                flag = True\n","                break\n","            if np.isnan(to_write[feature]):\n","                flag = True\n","                break\n","        to_write['id'] = row['id']\n","    \n","        if flag:\n","            continue\n","\n","        artists = literal_eval(row['artists'])\n","        seen_cluster = [False] * n_clusters\n","        seen_genres = set()\n","        \n","        for artist in artists:\n","            if artist in artist_map:\n","                for cluster in artist_map[artist]:\n","                    if not seen_cluster[cluster]:\n","                        temp_write = to_write.copy()\n","                        temp_write['cluster'] = int(cluster)\n","                        writer.writerow(temp_write)\n","                        seen_cluster[cluster] = True\n","\n","            if artist in artist_map_2:\n","                for cluster, genre in artist_map_2[artist]:\n","                    if genre not in seen_genres:\n","                        temp_write = to_write.copy()\n","                        temp_write['genre'] = genre\n","                        cluster_writers[cluster].writerow(temp_write)\n","                        seen_genres.add(genre)\n","\n","for f in cluster_files:\n","    f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7gdrySb2RKI"},"source":["topk = cluster_genres(df_cluster_hit)\n","topk = [x[0][:5] for x in topk]\n","topk = set([x for subl in topk for x in subl])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AdWSID3QOcBn"},"source":["df_comb = pd.DataFrame()\n","for i in range(n_clusters):\n","    df_temp = pd.read_csv(os.path.join(training_path, f'/genres/examples{i}.csv'))\n","    df_temp = df_temp[df_temp['genre'].isin(topk)]\n","    df_comb = pd.concat([df_comb, df_temp])\n","\n","group = df_comb.groupby('id')\n","\n","df_genre = group.first()\n","group_genres = group['genre'].apply(lambda x: list(set(x)))\n","df_genre['genre'] = group_genres\n","\n","X = df_genre.drop('genre', axis=1).to_numpy()\n","\n","mlb = MultiLabelBinarizer()\n","y = mlb.fit_transform(df_genre['genre'])\n","\n","X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=0.2)\n","\n","with open(os.path.join(training_path, f'/genres/X_train_all.pkl'), 'wb') as f:\n","    pickle.dump(X_train, f)\n","\n","with open(os.path.join(training_path + f'/genres/y_train_all.pkl'), 'wb') as f:\n","    pickle.dump(y_train, f)\n","\n","with open(os.path.join(training_path, f'/genres/X_test_all.pkl'), 'wb') as f:\n","    pickle.dump(X_test, f)\n","\n","with open(os.path.join(training_path, f'/genres/y_test_all.pkl'), 'wb') as f:\n","    pickle.dump(y_test, f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcscoVLjImiB"},"source":["# Figures\n","\n","We define a custom color palette to help distinguish between each cluster:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"v7A_UDwp_nQe","executionInfo":{"status":"ok","timestamp":1638146183684,"user_tz":360,"elapsed":35,"user":{"displayName":"Rodolfo Figueroa Soriano","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04776960717726066576"}},"outputId":"08faf0ad-6382-44a3-83ed-295f28054605"},"source":["def rgb_to_hex(rgb):\n","    return '#%02x%02x%02x' % rgb\n","\n","palette = [(235, 172, 35), (189, 189, 189), (0, 140, 249), (0, 110, 0), (184, 0, 88), (209, 99, 230), (135, 133, 0), (255, 146, 135), (0, 187, 173), (89, 84, 214), (0, 198, 248), (0, 167, 108), (178, 69, 2)]\n","palette_hex = [rgb_to_hex(p) for p in palette]\n","my_palette = sns.color_palette(palette_hex, 7)\n","my_palette"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<svg  width=\"385\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ebac23;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#bdbdbd;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#008cf9;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#006e00;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#b80058;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d163e6;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#878500;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"],"text/plain":["[(0.9215686274509803, 0.6745098039215687, 0.13725490196078433),\n"," (0.7411764705882353, 0.7411764705882353, 0.7411764705882353),\n"," (0.0, 0.5490196078431373, 0.9764705882352941),\n"," (0.0, 0.43137254901960786, 0.0),\n"," (0.7215686274509804, 0.0, 0.34509803921568627),\n"," (0.8196078431372549, 0.38823529411764707, 0.9019607843137255),\n"," (0.5294117647058824, 0.5215686274509804, 0.0)]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"pvlqojd-6FR0"},"source":["Projected points"]},{"cell_type":"code","metadata":{"id":"mDW3ZyuoHFq9"},"source":["sns.set(font_scale=1.2, style='white')\n","\n","fig, ax = plt.subplots(figsize=(16,14))\n","\n","sns.histplot(\n","    data = df_cluster,\n","    x = 'x',\n","    y = 'y',\n","    bins = 150,\n","    ax = ax\n",")\n","\n","label_text, label_coords = get_labels(df_cluster, popular=15, rep=4)\n","\n","sns.scatterplot(\n","    x = label_coords[:,0],\n","    y = label_coords[:,1],\n","    color = 'red',\n","    s = 30,\n","    legend = False,\n","    ax = ax,\n",")\n","\n","texts = [\n","    ax.text(x, y, name, ha='center', va='center', bbox=dict(boxstyle=\"round\", fc=\"white\", lw=0, alpha=0.6))\n","    for (x, y), name in zip(label_coords, label_text)\n","]\n","adjust_text(texts)\n","\n","ax.set_xlim(1, 16)\n","ax.set_ylim(-4, 10)\n","\n","fig.savefig(\"./drive/MyDrive/spotify/fig/projected.png\", bbox_inches='tight', dpi=150)\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ZN7iMa-6Hku"},"source":["Clustered points"]},{"cell_type":"code","metadata":{"id":"1EhB55bZJ3vT"},"source":["sns.set(font_scale=1.2, style='white')\n","fig, ax = plt.subplots(figsize=(16,14))\n","\n","sns.histplot(\n","    data = df_cluster_hit,\n","    x = 'x',\n","    y = 'y',\n","    hue = 'cluster',\n","    palette = my_palette,\n","    bins = 350,\n","    alpha = 1,\n","    ax = ax\n",")\n","\n","label_text, label_coords = get_labels(df_cluster_hit, popular=15, rep=4)\n","\n","sns.scatterplot(\n","    x = label_coords[:,0],\n","    y = label_coords[:,1],\n","    color = 'red',\n","    s = 30,\n","    legend = False,\n","    ax = ax,\n",")\n","\n","texts = [\n","    ax.text(x, y, name, ha='center', va='center', bbox=dict(boxstyle=\"round\", fc=\"white\", lw=0, alpha=0.6))\n","    for (x, y), name in zip(label_coords, label_text)\n","]\n","adjust_text(texts)\n","\n","ax.set_xlim(1, 16)\n","ax.set_ylim(-4, 10)\n","\n","fig.savefig(f\"./drive/MyDrive/spotify/fig/cluster_{n_clusters}.png\", bbox_inches='tight', dpi=150)\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7mcoTi76I0Z"},"source":["`n` most common genres in each cluster."]},{"cell_type":"code","metadata":{"id":"WQUva8zrImB1"},"source":["sns.set(font_scale=2.5, style='white')\n","\n","n = 15\n","temp = list(cluster_genres(df_cluster_hit))\n","for i, (genres, counts) in enumerate(temp):\n","    genres, counts = genres[:n], counts[:n]\n","    \n","    fig, ax = plt.subplots(figsize=(10,14))\n","    sns.barplot(\n","        y = genres,\n","        x = counts,\n","        palette = 'mako'\n","    )\n","    ax.set_xlabel(\"Número de apariciones\")\n","    ax.set_ylabel(\"Género\")\n","    ax.set_title(f\"Cluster {i}\")\n","    fig.savefig(f\"./drive/MyDrive/spotify/fig/bar_{i}.png\", bbox_inches='tight', dpi=150)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ryb_0tI66OI5"},"source":["Feature distribution for each cluster"]},{"cell_type":"code","metadata":{"id":"qML1DDL0QeTC"},"source":["sns.set(font_scale=2, style='white')\n","\n","df_artists_merge = df_artists.copy()\n","df_artists_merge['id'] = artist_ids\n","df_artists_merge = df_artists_merge.set_index('id')\n","df_artists_merge = df_artists_merge.join(df_cluster_hit)\n","df_artists_merge = df_artists_merge.dropna()\n","df_artists_merge = df_artists_merge.sort_values('cluster')\n","df_artists_merge['cluster'] = df_artists_merge['cluster'].astype(int).astype(str)\n","\n","for feature in feature_cols:\n","    fig, ax = plt.subplots(figsize=(10,8))\n","    sns.violinplot(\n","        data = df_artists_merge,\n","        x = 'cluster',\n","        y = feature + '_avg',\n","        palette = my_palette,\n","        ax = ax\n","    )\n","    ax.set_xlabel(\"Cluster\")\n","    ax.set_ylabel('')\n","    ax.set_title(feature.title())\n","    fig.savefig(f\"./drive/MyDrive/spotify/fig/cluster_{feature}.png\", bbox_inches='tight', dpi=150)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSPpEJU66QtZ"},"source":["Histograms for each feature across all points"]},{"cell_type":"code","metadata":{"id":"f48QJhgn05ub"},"source":["sns.set(font_scale=1.5, style='white')\n","\n","for feature in feature_cols:\n","    fig, ax = plt.subplots(figsize=(10,8))\n","    sns.histplot(\n","        data = df_artists,\n","        x = feature + '_avg',\n","        palette = 'mako',\n","        stat = 'density',\n","        ax = ax\n","    )\n","    ax.set_xlabel('')\n","    ax.set_ylabel('Densidad')\n","    ax.set_title(feature.title())\n","    fig.savefig(f\"./drive/MyDrive/spotify/fig/hist_{feature}.png\", bbox_inches='tight', dpi=150)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUlv9oUa6Tkj"},"source":["Joint plots for each possible feature combination"]},{"cell_type":"code","metadata":{"id":"JvGJbRFz1tiP"},"source":["sns.set(font_scale=1.5)\n","for i,feature1 in enumerate(feature_cols):\n","    for feature2 in feature_cols[i+1:]:\n","        fig, ax = plt.subplots(figsize=(10,8))\n","        sns.histplot(\n","            data = df_artists,\n","            x = feature1 + '_avg',\n","            y = feature2 + '_avg',\n","            ax = ax\n","        )\n","        ax.set_xlabel(feature1.title())\n","        ax.set_ylabel(feature2.title())\n","        ax.set_title(f\"{feature1.title()} vs. {feature2.title()}\")\n","        fig.savefig(f\"./drive/MyDrive/spotify/fig/joint_{feature1}_{feature2}.png\", bbox_inches='tight', dpi=150)\n","        plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GFne6XeELbF"},"source":["i = 0\n","temp = {to_uuid(key): value for key, value in artist_map_2.items() if any([v[0]==i for v in value])}\n","df_temp = pd.DataFrame([temp]).T\n","df_temp = df_temp.explode(0)\n","df_temp = pd.DataFrame(df_temp[0].tolist(), index=df_temp.index, columns=['cluster', 'genre'])\n","df_temp = df_temp[df_temp['cluster']==i]\n","df_temp = df_temp.drop('cluster', axis=1)\n","df_temp = df_temp.join(df_cluster)\n","df_temp = df_temp[['name', 'x', 'y', 'genre']]\n","\n","fig, ax = plt.subplots(figsize=(14,14))\n","sns.scatterplot(\n","    data = df_temp,\n","    x = 'x',\n","    y = 'y',\n","    hue = 'genre',\n","    linewidth = 0\n",")\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6B0CLIl6XC7"},"source":[""],"execution_count":null,"outputs":[]}]}